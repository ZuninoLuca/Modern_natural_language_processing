{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing of the 'interactions' dataset to compute BERTScores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we process the 'interactions' dataset to determine the candidate answer for each datapoint. Since almost of datapoints contain a multi-turn interaction, we determine our candidate answer by considering the assistant answer that has the highest semantic similarity (determined computing the BERTScore) with the golden answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bert-score # https://pypi.org/project/bert-score/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data\n",
    "with open('interactions_v1.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON solutions\n",
    "with open('solutions_v1.json', 'r') as file:\n",
    "    solutions = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_and_concatenate(nested_list):\n",
    "    # If the input is a string, return it\n",
    "    if isinstance(nested_list, str):\n",
    "        return nested_list\n",
    "\n",
    "    # If the input is a list, apply the function to each element and concatenate the results\n",
    "    if isinstance(nested_list, list):\n",
    "        return ' '.join(flatten_and_concatenate(element) for element in nested_list)\n",
    "\n",
    "    # If the input is neither a string nor a list, return an empty string\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Create an empty list to store the datapoints\n",
    "datapoints = []\n",
    "complete_data = []\n",
    "\n",
    "try:\n",
    "    # Load the previous list of datapoints (used to resume the process if it was interrupted)\n",
    "    with open('datapoints.json', 'r') as f:\n",
    "        datapoints = json.load(f)\n",
    "    with open('complete.json', 'r') as f:\n",
    "        complete_data = json.load(f)\n",
    "\n",
    "    start_index = len(datapoints)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load previous data: {e}\")\n",
    "    \n",
    "data_len = len(data)\n",
    "start_time = time.time()\n",
    "elapsed_times = []\n",
    "\n",
    "# Iterate over the data\n",
    "for count, datapoint in enumerate(data[start_index:], start_index + 1):\n",
    "    try:\n",
    "        print(\"########################################################\")\n",
    "        print(\"Processing datapoint\", count, \"of\", data_len, \"(\", round(count/data_len*100, 2), \"%)\")\n",
    "        print(\"########################################################\")\n",
    "\n",
    "        iteration_start_time = time.time()\n",
    "        max_score = -1\n",
    "        best_content = ''\n",
    "        gold_answer = ''\n",
    "        explanation = None\n",
    "        is_mcq = 0\n",
    "\n",
    "        # Iterate over the entries in the data\n",
    "        for entry in solutions:\n",
    "            # If the sol_id of the current entry matches the target sol_id\n",
    "            if entry.get('sol_id') == datapoint.get(\"sol_id\"):\n",
    "                gold_answer = entry.get('answer', '')\n",
    "                if 'choices' in entry:\n",
    "                    is_mcq = 1\n",
    "                if 'explanation' in entry and entry['explanation'] is not None:\n",
    "                    explanation = entry['explanation']\n",
    "                break\n",
    "\n",
    "        interactions = []\n",
    "        # Iterate over the interactions in the data\n",
    "        for interaction in datapoint.get('interaction', []):\n",
    "            # Check if the role is 'assistant'\n",
    "            if interaction.get('role') == 'assistant':\n",
    "                # Compute the BERTScore for the content of the interaction\n",
    "                if isinstance(interaction.get('content'), str):\n",
    "                    score_ = score([interaction['content']], [flatten_and_concatenate(gold_answer)], model_type=\"bert-base-multilingual-cased\")[2]\n",
    "\n",
    "                    # Convert tensor to a single value\n",
    "                    score_ = score_.item()\n",
    "\n",
    "                # If the computed score is higher than the current max score,\n",
    "                # update max_score and best_content\n",
    "                if score_ > max_score:\n",
    "                    max_score = score_\n",
    "                    best_content = interaction['content']\n",
    "\n",
    "                interaction[\"BERTScore\"] = float(score_)\n",
    "\n",
    "            interactions.append(interaction)\n",
    "\n",
    "        # Create a dictionary to store the datapoint\n",
    "        if is_mcq and explanation is not None:\n",
    "            datapoint_dict = {\n",
    "                \"candidate_answer\": best_content,\n",
    "                \"gold_answer\": gold_answer,\n",
    "                \"max_score\": max_score,\n",
    "                \"MCQ\": is_mcq,\n",
    "                \"explanation\": explanation\n",
    "            }\n",
    "        else:\n",
    "            datapoint_dict = {\n",
    "                \"candidate_answer\": best_content,\n",
    "                \"gold_answer\": gold_answer,\n",
    "                \"max_score\": max_score,\n",
    "                \"MCQ\": is_mcq\n",
    "            }\n",
    "\n",
    "        # Add the datapoint to the list\n",
    "        datapoints.append(datapoint_dict)\n",
    "\n",
    "        complete_data.append({\n",
    "            \"confidence\": datapoint.get(\"confidence\", None),\n",
    "            \"interaction\": interactions\n",
    "        })\n",
    "\n",
    "        iteration_end_time = time.time()\n",
    "        elapsed_time = iteration_end_time - iteration_start_time\n",
    "        elapsed_times.append(elapsed_time)\n",
    "\n",
    "        average_time_per_datapoint = sum(elapsed_times) / len(elapsed_times)\n",
    "        remaining_datapoints = data_len - count\n",
    "        estimated_time_remaining = remaining_datapoints * average_time_per_datapoint\n",
    "\n",
    "        print(\"Estimated time remaining: \", round(estimated_time_remaining/60, 2), \"minutes\")\n",
    "\n",
    "        # Save the list of datapoints as a JSON file\n",
    "        with open('datapoints.json', 'w') as f:\n",
    "            json.dump(datapoints, f)\n",
    "\n",
    "        # Save the complete data with BERTScore for each interaction\n",
    "        with open('complete.json', 'w') as f:\n",
    "            json.dump(complete_data, f)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed on datapoint {count}: {e}\")\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
