{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texas University Dataset\n",
    "\n",
    "This notebook collects information from many different txt files of the datasetinto one json that has a chat, question number, entry id, and a grade for every answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the contents of the text file\n",
    "with open(\"texas/data/sent/all.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "with open(\"texas/data/sent/questions.txt\", \"r\") as file:\n",
    "    questions_text = file.read()\n",
    "\n",
    "with open(\"texas/data/sent/answers.txt\", \"r\") as file:\n",
    "    answers_text = file.read()\n",
    "\n",
    "# Extract question numbers and remove \"<STOP>\" tokens\n",
    "question_numbers = re.findall(r'^(\\d+\\.\\d+)', text, flags=re.MULTILINE)\n",
    "cleaned_text = text.replace(\"<STOP>\", \"\")\n",
    "non_repeated_questions = re.findall(r'^(\\d+\\.\\d+)', questions_text, flags=re.MULTILINE)\n",
    "\n",
    "# Print the extracted question numbers\n",
    "# for number in question_numbers:\n",
    "#     print(number)\n",
    "\n",
    "# Save the cleaned text to a new file\n",
    "# with open(\"cleaned_answers.txt\", \"w\") as file:\n",
    "#     file.write(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = cleaned_text.split('\\n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = {}\n",
    "question_blocks = re.split(r'(\\d+\\.\\d+)', questions_text)\n",
    "for i in range(1, len(question_blocks), 2):\n",
    "    question_number = question_blocks[i]\n",
    "    question = question_blocks[i + 1].strip()\n",
    "    question = question.replace(\"<STOP>\", \"\")\n",
    "    questions[question_number] = question\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}\n",
    "answers_blocks = re.split(r'(\\d+\\.\\d+)', answers_text)\n",
    "for i in range(1, len(answers_blocks), 2):\n",
    "    answers_number = answers_blocks[i]\n",
    "    answer = answers_blocks[i + 1].strip()\n",
    "    answer = answer.replace(\"<STOP>\", \"\")\n",
    "    answers[answers_number] = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"texas/data/all_scores/\"  # Replace with the path to your folder\n",
    "float_questions = sorted([float(x) for x in set(question_numbers)])\n",
    "grade_files = []\n",
    "flag = True\n",
    "for question_number in float_questions:\n",
    "    if(flag):\n",
    "        grade_file = os.path.join(folder_path, str(question_number) + \".txt\")\n",
    "        grade_files.append(grade_file)\n",
    "    else:\n",
    "        flag = True\n",
    "\n",
    "    if(question_number == 11.9):\n",
    "        grade_file = os.path.join(folder_path, '11.10' + \".txt\")\n",
    "        grade_files.append(grade_file)\n",
    "        flag = False\n",
    "\n",
    "\n",
    "grade_file = os.path.join(folder_path, '12.10' + \".txt\")\n",
    "grade_files.append(grade_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "grade_files = list(OrderedDict.fromkeys(grade_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grade_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = []\n",
    "grades = []\n",
    "for file_path in grade_files:\n",
    "    if file_path.endswith(\".txt\"):\n",
    "        all_grades = []\n",
    "        with open(file_path, \"r\") as file:\n",
    "            file_content = file.read()\n",
    "            if file_content:\n",
    "                lines = file_content.split(\"\\n\")\n",
    "                for line in lines:\n",
    "                    if line != \"\":\n",
    "                        grades.append(line)\n",
    "                        all_grades.append(line)\n",
    "        unique.append(len(set(all_grades)))\n",
    "\n",
    "grades = [float(x) for x in grades]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique\n",
    "eval_questions = [non_repeated_questions[index] for index, element in enumerate(unique) if element < 4]\n",
    "len(eval_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "count = 0\n",
    "\n",
    "prev_question_number = 0\n",
    "for idx,(number, student_answer) in enumerate(zip(question_numbers, cleaned_text)):\n",
    "    \n",
    "    # if prev_question_number != number:\n",
    "    #     data.append({\n",
    "    #         'entry_id': count,\n",
    "    #         'chat': \"Human: \"+questions[number] + \"\\n\\nAssistant: \" + answers[number],\n",
    "    #         # 'question': questions[number],\n",
    "    #         # 'answer': answers[number],\n",
    "    #         'label': \"positive\"\n",
    "    #     })\n",
    "    #     prev_question_number = number\n",
    "    #     count += 1\n",
    "    data.append({\n",
    "        'entry_id': count,\n",
    "        'question_number': number,\n",
    "        'chat': \"Human: \"+questions[number] + \"\\n\\nAssistant: \" +  re.sub(r'^\\d+\\.\\d+\\s+', '',student_answer, count = 1),\n",
    "        # 'question':  questions[number],\n",
    "        # 'answer': re.sub(r'^\\d+\\.\\d+\\s+', '',student_answer, count = 1),\n",
    "        'grade': grades[idx]\n",
    "    })\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('texas_data.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Read the JSON file and parse its contents\n",
    "with open('texas_data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Group the entries based on question numbers\n",
    "groups = {}\n",
    "for entry in data:\n",
    "    question_number = entry['question_number']\n",
    "    if question_number not in groups:\n",
    "        groups[question_number] = []\n",
    "    groups[question_number].append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_groups = {key: groups[key] for key in list(groups.keys()) if key in eval_questions}\n",
    "train_groups = {key: groups[key] for key in list(groups.keys()) if key not in eval_questions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_entries = []\n",
    "unsampled_entries = []\n",
    "\n",
    "# Iterate over each group and sample 5 unique grades or add all entries if unique grades < 5\n",
    "for question_number, entries in train_groups.items():\n",
    "    unique_grades = list(set(entry['grade'] for entry in entries))\n",
    "    \n",
    "    if 5.0 in unique_grades:\n",
    "        unique_grades.remove(5.0)\n",
    "        sampled_grades = random.sample(unique_grades, min(3, len(unique_grades)))\n",
    "        sampled_grades.append(5.0)\n",
    "    else:\n",
    "        sampled_grades = random.sample(unique_grades, min(4, len(unique_grades)))\n",
    "    ordered_entries = sorted(entries, key=lambda entry: entry['grade'],  reverse=True)\n",
    "    sampled_grades = sorted(sampled_grades, reverse=True)\n",
    "\n",
    "    if len(unique_grades) < 4:\n",
    "        continue\n",
    "    \n",
    "    for entry in ordered_entries:\n",
    "        if entry['grade'] in sampled_grades:\n",
    "            sampled_entries.append(entry)\n",
    "            sampled_grades.remove(entry['grade'])\n",
    "        else:\n",
    "            unsampled_entries.append(entry)\n",
    "\n",
    "\n",
    "# Save the sampled entries in a new JSON file\n",
    "with open('train_data1.json', 'w') as file:\n",
    "    json.dump(sampled_entries, file, indent=4)\n",
    "\n",
    "# Save the unsampled entries in another JSON file\n",
    "with open('unsampled_data1.json', 'w') as file:\n",
    "    json.dump(unsampled_entries, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Read the JSON file and parse its contents\n",
    "with open('unsampled_data1.json', 'r') as file:\n",
    "    unsampled_data = json.load(file)\n",
    "\n",
    "# Group the entries based on question numbers\n",
    "groups = {}\n",
    "for entry in unsampled_data:\n",
    "    question_number = entry['question_number']\n",
    "    if question_number not in groups:\n",
    "        groups[question_number] = []\n",
    "    groups[question_number].append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_entries = []\n",
    "unsampled_entries = []\n",
    "\n",
    "# Iterate over each group and sample 5 unique grades or add all entries if unique grades < 5\n",
    "for question_number, entries in groups.items():\n",
    "    unique_grades = list(set(entry['grade'] for entry in entries))\n",
    "    \n",
    "    if 5.0 in unique_grades:\n",
    "        unique_grades.remove(5.0)\n",
    "        sampled_grades = random.sample(unique_grades, min(3, len(unique_grades)))\n",
    "        sampled_grades.append(5.0)\n",
    "    else:\n",
    "        sampled_grades = random.sample(unique_grades, min(4, len(unique_grades)))\n",
    "    ordered_entries = sorted(entries, key=lambda entry: entry['grade'],  reverse=True)\n",
    "    sampled_grades = sorted(sampled_grades, reverse=True)\n",
    "    \n",
    "    if len(unique_grades) < 4:\n",
    "        continue\n",
    "    \n",
    "    for entry in ordered_entries:\n",
    "        if entry['grade'] in sampled_grades:\n",
    "            sampled_entries.append(entry)\n",
    "            sampled_grades.remove(entry['grade'])\n",
    "        else:\n",
    "            unsampled_entries.append(entry)\n",
    "            \n",
    "        \n",
    "\n",
    "# Save the sampled entries in a new JSON file\n",
    "with open('train_data2.json', 'w') as file:\n",
    "    json.dump(sampled_entries, file, indent=4)\n",
    "\n",
    "# Save the unsampled entries in another JSON file\n",
    "with open('unsampled_data2.json', 'w') as file:\n",
    "    json.dump(unsampled_entries, file, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampled_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Read the JSON file and parse its contents\n",
    "with open('unsampled_data2.json', 'r') as file:\n",
    "    unsampled_data = json.load(file)\n",
    "\n",
    "# Group the entries based on question numbers\n",
    "groups = {}\n",
    "for entry in unsampled_data:\n",
    "    question_number = entry['question_number']\n",
    "    if question_number not in groups:\n",
    "        groups[question_number] = []\n",
    "    groups[question_number].append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_entries = []\n",
    "unsampled_entries = []\n",
    "\n",
    "# Iterate over each group and sample 5 unique grades or add all entries if unique grades < 5\n",
    "for question_number, entries in groups.items():\n",
    "    unique_grades = list(set(entry['grade'] for entry in entries))\n",
    "    \n",
    "    if 5.0 in unique_grades:\n",
    "        unique_grades.remove(5.0)\n",
    "        sampled_grades = random.sample(unique_grades, min(3, len(unique_grades)))\n",
    "        sampled_grades.append(5.0)\n",
    "    else:\n",
    "        sampled_grades = random.sample(unique_grades, min(4, len(unique_grades)))\n",
    "    ordered_entries = sorted(entries, key=lambda entry: entry['grade'],  reverse=True)\n",
    "    sampled_grades = sorted(sampled_grades, reverse=True)\n",
    "    \n",
    "    if len(unique_grades) < 4:\n",
    "        continue\n",
    "    \n",
    "    for entry in ordered_entries:\n",
    "        if entry['grade'] in sampled_grades:\n",
    "            sampled_entries.append(entry)\n",
    "            sampled_grades.remove(entry['grade'])\n",
    "        else:\n",
    "            unsampled_entries.append(entry)\n",
    "            \n",
    "        \n",
    "\n",
    "# Save the sampled entries in a new JSON file\n",
    "with open('train_data3.json', 'w') as file:\n",
    "    json.dump(sampled_entries, file, indent=4)\n",
    "\n",
    "# Save the unsampled entries in another JSON file\n",
    "with open('unsampled_data3.json', 'w') as file:\n",
    "    json.dump(unsampled_entries, file, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampled_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Read the JSON file and parse its contents\n",
    "with open('unsampled_data3.json', 'r') as file:\n",
    "    unsampled_data = json.load(file)\n",
    "\n",
    "# Group the entries based on question numbers\n",
    "groups = {}\n",
    "for entry in unsampled_data:\n",
    "    question_number = entry['question_number']\n",
    "    if question_number not in groups:\n",
    "        groups[question_number] = []\n",
    "    groups[question_number].append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_entries = []\n",
    "unsampled_entries = []\n",
    "\n",
    "# Iterate over each group and sample 5 unique grades or add all entries if unique grades < 5\n",
    "for question_number, entries in groups.items():\n",
    "    unique_grades = list(set(entry['grade'] for entry in entries))\n",
    "    \n",
    "    if 5.0 in unique_grades:\n",
    "        unique_grades.remove(5.0)\n",
    "        sampled_grades = random.sample(unique_grades, min(3, len(unique_grades)))\n",
    "        sampled_grades.append(5.0)\n",
    "    else:\n",
    "        sampled_grades = random.sample(unique_grades, min(4, len(unique_grades)))\n",
    "    ordered_entries = sorted(entries, key=lambda entry: entry['grade'],  reverse=True)\n",
    "    sampled_grades = sorted(sampled_grades, reverse=True)\n",
    "    \n",
    "    if len(unique_grades) < 4:\n",
    "        continue\n",
    "    \n",
    "    for entry in ordered_entries:\n",
    "        if entry['grade'] in sampled_grades:\n",
    "            sampled_entries.append(entry)\n",
    "            sampled_grades.remove(entry['grade'])\n",
    "        else:\n",
    "            unsampled_entries.append(entry)\n",
    "            \n",
    "        \n",
    "\n",
    "# Save the sampled entries in a new JSON file\n",
    "with open('train_data4.json', 'w') as file:\n",
    "    json.dump(sampled_entries, file, indent=4)\n",
    "\n",
    "# Save the unsampled entries in another JSON file\n",
    "with open('unsampled_data4.json', 'w') as file:\n",
    "    json.dump(unsampled_entries, file, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampled_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Read the JSON file and parse its contents\n",
    "with open('unsampled_data4.json', 'r') as file:\n",
    "    unsampled_data = json.load(file)\n",
    "\n",
    "# Group the entries based on question numbers\n",
    "groups = {}\n",
    "for entry in unsampled_data:\n",
    "    question_number = entry['question_number']\n",
    "    if question_number not in groups:\n",
    "        groups[question_number] = []\n",
    "    groups[question_number].append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_entries = []\n",
    "unsampled_entries = []\n",
    "\n",
    "# Iterate over each group and sample 5 unique grades or add all entries if unique grades < 5\n",
    "for question_number, entries in groups.items():\n",
    "    unique_grades = list(set(entry['grade'] for entry in entries))\n",
    "    \n",
    "    if 5.0 in unique_grades:\n",
    "        unique_grades.remove(5.0)\n",
    "        sampled_grades = random.sample(unique_grades, min(3, len(unique_grades)))\n",
    "        sampled_grades.append(5.0)\n",
    "    else:\n",
    "        sampled_grades = random.sample(unique_grades, min(4, len(unique_grades)))\n",
    "    ordered_entries = sorted(entries, key=lambda entry: entry['grade'],  reverse=True)\n",
    "    sampled_grades = sorted(sampled_grades, reverse=True)\n",
    "    \n",
    "    if len(unique_grades) < 4:\n",
    "        continue\n",
    "    \n",
    "    for entry in ordered_entries:\n",
    "        if entry['grade'] in sampled_grades:\n",
    "            sampled_entries.append(entry)\n",
    "            sampled_grades.remove(entry['grade'])\n",
    "        else:\n",
    "            unsampled_entries.append(entry)\n",
    "            \n",
    "        \n",
    "\n",
    "# Save the sampled entries in a new JSON file\n",
    "with open('train_data5.json', 'w') as file:\n",
    "    json.dump(sampled_entries, file, indent=4)\n",
    "\n",
    "# Save the unsampled entries in another JSON file\n",
    "with open('unsampled_data5.json', 'w') as file:\n",
    "    json.dump(unsampled_entries, file, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampled_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Read the JSON file and parse its contents\n",
    "with open('unsampled_data4.json', 'r') as file:\n",
    "    unsampled_data = json.load(file)\n",
    "\n",
    "# Group the entries based on question numbers\n",
    "groups = {}\n",
    "for entry in unsampled_data:\n",
    "    question_number = entry['question_number']\n",
    "    if question_number not in groups:\n",
    "        groups[question_number] = []\n",
    "    groups[question_number].append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_entries = []\n",
    "unsampled_entries = []\n",
    "\n",
    "# Iterate over each group and sample 5 unique grades or add all entries if unique grades < 5\n",
    "for question_number, entries in groups.items():\n",
    "    unique_grades = list(set(entry['grade'] for entry in entries))\n",
    "    \n",
    "    if 5.0 in unique_grades:\n",
    "        unique_grades.remove(5.0)\n",
    "        sampled_grades = random.sample(unique_grades, min(3, len(unique_grades)))\n",
    "        sampled_grades.append(5.0)\n",
    "    else:\n",
    "        sampled_grades = random.sample(unique_grades, min(4, len(unique_grades)))\n",
    "    ordered_entries = sorted(entries, key=lambda entry: entry['grade'],  reverse=True)\n",
    "    sampled_grades = sorted(sampled_grades, reverse=True)\n",
    "    \n",
    "    if len(unique_grades) < 4:\n",
    "        continue\n",
    "    \n",
    "    for entry in ordered_entries:\n",
    "        if entry['grade'] in sampled_grades:\n",
    "            sampled_entries.append(entry)\n",
    "            sampled_grades.remove(entry['grade'])\n",
    "        else:\n",
    "            unsampled_entries.append(entry)\n",
    "            \n",
    "        \n",
    "\n",
    "# Save the sampled entries in a new JSON file\n",
    "with open('train_data6.json', 'w') as file:\n",
    "    json.dump(sampled_entries, file, indent=4)\n",
    "\n",
    "# Save the unsampled entries in another JSON file\n",
    "with open('unsampled_data6.json', 'w') as file:\n",
    "    json.dump(unsampled_entries, file, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampled_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_entries = []\n",
    "bad_sampled_entries = []\n",
    "# Iterate over the dictionary\n",
    "for question_number, entries in eval_groups.items():\n",
    "    grade_5_entries = [entry for entry in entries if entry['grade'] == 5.0]\n",
    "    bad_grades_entries = [entry for entry in entries if entry['grade'] <= 3.5]\n",
    "    # Sample 4 entries if there are at least 4 grade 5 entries\n",
    "    if len(grade_5_entries) >= 4:\n",
    "        sampled_entries.extend(random.sample(grade_5_entries, 4))\n",
    "    if len(bad_grades_entries) >= 3:\n",
    "        bad_sampled_entries.extend(random.sample(bad_grades_entries, 4))\n",
    "        \n",
    "# Add the label \"positive\" to the sampled entries\n",
    "for entry in sampled_entries:\n",
    "    entry['label'] = 'positive'\n",
    "for entry in bad_sampled_entries:\n",
    "    entry['label'] = 'negative'\n",
    "eval_entries = sampled_entries + bad_sampled_entries\n",
    "# Save the sampled entries in a JSON file\n",
    "with open('eval_data.json', 'w') as file:\n",
    "    json.dump(eval_entries, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entry_id': 802,\n",
       "  'question_number': '4.6',\n",
       "  'chat': 'Human: Using an index outside the bounds of the array generates an error.  Is this a compilation error or a run-time error? \\n\\nAssistant: compilation error. ',\n",
       "  'grade': 1.0,\n",
       "  'label': 'negative'},\n",
       " {'entry_id': 804,\n",
       "  'question_number': '4.6',\n",
       "  'chat': 'Human: Using an index outside the bounds of the array generates an error.  Is this a compilation error or a run-time error? \\n\\nAssistant: not answered ',\n",
       "  'grade': 0.0,\n",
       "  'label': 'negative'},\n",
       " {'entry_id': 807,\n",
       "  'question_number': '4.6',\n",
       "  'chat': 'Human: Using an index outside the bounds of the array generates an error.  Is this a compilation error or a run-time error? \\n\\nAssistant: compilation error ',\n",
       "  'grade': 1.0,\n",
       "  'label': 'negative'}]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_sampled_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
