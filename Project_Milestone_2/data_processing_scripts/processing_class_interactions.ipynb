{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing of the 'interactions' dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we process the 'interactions' dataset to be able to employ it to train (and test) our reward model. In particular, we decide which interactions to include, we ensure the interaction length is within the maximum context length of RoBERTa, and we split the dataset into a training dataset and an evaluation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "# Initialize RoBERTa tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Load JSON file\n",
    "def load_json(file):\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Write to JSON file\n",
    "def write_json(file, data):\n",
    "    with open(file, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "# Maximum content length for RoBERTa model\n",
    "MAX_LEN = 512\n",
    "\n",
    "# Load data\n",
    "data = load_json('complete_addition_QA.json')\n",
    "\n",
    "# Step 1: Modify \"interaction\" content\n",
    "for d in data:\n",
    "    # Sorting by BERTScore (only assistant role has BERTScore)\n",
    "    assistant_interactions = [i for i in d['interaction'] if i['role'] == 'assistant']\n",
    "    assistant_interactions.sort(key=lambda x: x.get('BERTScore', -1), reverse=True)\n",
    "    \n",
    "    final_interactions = []\n",
    "    content_len = 0\n",
    "\n",
    "    for inter in assistant_interactions:\n",
    "        idx = d['interaction'].index(inter)\n",
    "        if idx > 0 and d['interaction'][idx-1]['role'] == 'user':\n",
    "            combined_len = len(tokenizer(inter['content']).input_ids) + len(tokenizer(d['interaction'][idx-1]['content']).input_ids)\n",
    "            if content_len + combined_len <= MAX_LEN:\n",
    "                final_interactions.extend([d['interaction'][idx-1], inter])\n",
    "                content_len += combined_len\n",
    "        elif idx > 0 and d['interaction'][idx-1]['role'] == 'system':\n",
    "            combined_len = len(tokenizer(inter['content']).input_ids) + len(tokenizer(d['interaction'][idx-1]['content']).input_ids)\n",
    "            if content_len + combined_len <= MAX_LEN:\n",
    "                final_interactions.extend([d['interaction'][idx-1], inter])\n",
    "                content_len += combined_len\n",
    "    \n",
    "    # Sort interactions by their original order\n",
    "    final_interactions.sort(key=lambda x: d['interaction'].index(x))\n",
    "\n",
    "    d['interaction'] = final_interactions\n",
    "\n",
    "# Save modified data\n",
    "write_json('modified_data.json', data)\n",
    "\n",
    "# Step 2: Split the datapoints in a training and a testing set according to a ratio passed by the user\n",
    "def split_data(data, ratio):\n",
    "    sol_ids = np.unique([d['sol_id'] for d in data])\n",
    "    train_ids, test_ids = train_test_split(sol_ids, test_size=ratio, random_state=0)\n",
    "\n",
    "    train_data = [d for d in data if d['sol_id'] in train_ids]\n",
    "    test_data = [d for d in data if d['sol_id'] in test_ids]\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, test_data = split_data(data, 0.3)\n",
    "\n",
    "print(f\"Training data: {len(train_data)}\")\n",
    "print(f\"Testing data: {len(test_data)}\")\n",
    "\n",
    "# Save training and testing data\n",
    "write_json('class_train_data.json', train_data)\n",
    "write_json('class_test_data.json', test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we add the field \"score\" to the train and test datasets (present in a separate dataset) and we process the test dataset so that, for every group of three examples, just two (the best one and the worse one) are kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RoBERTa tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Maximum content length for RoBERTa model\n",
    "MAX_LEN = 512\n",
    "\n",
    "# Load JSON file\n",
    "def load_json(file):\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Write to JSON file\n",
    "def write_json(file, data):\n",
    "    with open(file, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "# Load the modified data\n",
    "train_data = load_json('class_train_data.json')\n",
    "test_data = load_json('class_test_data.json')\n",
    "\n",
    "# Step 1: Check whether the concatenated length of each \"content\" for each \"interaction\" is below the limit\n",
    "for data_set in [train_data, test_data]:\n",
    "    for d in data_set:\n",
    "        concatenated_content = ' '.join([i['content'] for i in d['interaction']])\n",
    "        content_len = len(tokenizer.encode(concatenated_content, truncation=False))\n",
    "        if content_len > MAX_LEN:\n",
    "            raise ValueError(f\"Content length for datapoint {d['interaction_id']} exceeds the limit\")\n",
    "\n",
    "# Load the complete_with_grades.json\n",
    "grades_data = load_json('complete_complete_with_grades.json')\n",
    "sol_id_to_grade = {d['sol_id']: d['score'] for d in grades_data}\n",
    "\n",
    "# Step 2: Add the field \"score\" to the train and test datasets\n",
    "invalid_scores = 0\n",
    "for data_set in [train_data, test_data]:\n",
    "    for d in data_set:\n",
    "        d['score'] = sol_id_to_grade.get(d['sol_id'], -1)\n",
    "        if d['score'] == -1:\n",
    "            invalid_scores += 1\n",
    "\n",
    "print(f\"Invalid scores assigned: {invalid_scores}\")\n",
    "\n",
    "# Save datasets with scores\n",
    "write_json('class_train_data_with_scores.json', train_data)\n",
    "write_json('class_test_data_with_scores.json', test_data)\n",
    "\n",
    "# Step 3: Process the test dataset so that, for every group of three examples, just two are kept\n",
    "def process_test_data(data):\n",
    "    sol_ids = set(d['sol_id'] for d in data)\n",
    "    new_data = []\n",
    "    \n",
    "    for sol_id in sol_ids:\n",
    "        group = [d for d in data if d['sol_id'] == sol_id]\n",
    "        valid_group = [d for d in group if d['score'] != -1]\n",
    "        if len(valid_group) < 2:\n",
    "            continue\n",
    "        valid_group.sort(key=lambda x: x['score'])\n",
    "        \n",
    "        for idx, d in enumerate(valid_group):\n",
    "            chat = \"\"\n",
    "            for interaction in d['interaction']:\n",
    "                chat += f\"{interaction['role'].capitalize()}: {interaction['content']} \\n\\n\"\n",
    "            new_chat = chat.replace(\"User:\", \"Human:\")\n",
    "            label = \"chosen\" if idx == len(valid_group)-1 else \"rejected\"  # highest score -> positive, lowest -> negative\n",
    "            if idx == len(valid_group)-1:\n",
    "                positive_chat = new_chat\n",
    "            if idx == 0:\n",
    "                negative_chat = new_chat\n",
    "        if positive_chat != \"\" and negative_chat != \"\" and positive_chat != negative_chat:\n",
    "            new_data.append({\"chosen\": positive_chat, \"rejected\": negative_chat})\n",
    "\n",
    "    return new_data\n",
    "\n",
    "test_data = process_test_data(test_data)\n",
    "write_json('class_processed_test_data.json', test_data)\n",
    "\n",
    "# Process the training data to add \"chat\" field\n",
    "def process_train_data(data):\n",
    "    new_data = []\n",
    "\n",
    "    for d in data:\n",
    "        chat = \"\"\n",
    "        for interaction in d['interaction']:\n",
    "            chat += f\"{interaction['role'].capitalize()}: {interaction['content']} \\n\\n\"\n",
    "        new_chat = chat.replace(\"User:\", \"Human:\")\n",
    "        d[\"chat\"] = new_chat\n",
    "        if new_chat != \"\":\n",
    "            new_data.append(d)\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "train_data = process_train_data(train_data)\n",
    "write_json('class_processed_train_data.json', train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
