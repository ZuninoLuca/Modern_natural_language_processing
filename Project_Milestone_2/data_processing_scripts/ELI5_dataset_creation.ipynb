{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to obtain the ELI5 dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we prompt ChatGPT using the gpt_wrapper in order to obtain the ELI5 dataset used to train our reward model. In particular, we start from the dataset 'eli5_category' available on [HuggingFace](https://huggingface.co/datasets/eli5_category), considering the answer with the higher number of upvotes as the golden answer. Than, we prompt ChatGPT to obtain worse answers to the same questions, specifying the errors we would like to have in the worse answers, and the grade associated with each answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install artifacts/gpt_wrapper-0.0.8-py3-none-any.whl\n",
    "%pip install tiktoken\n",
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_wrapper\n",
    "gpt_wrapper.api_key = \"GPT_KEY_REMOVED_FOR_PRIVACY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_wrapper.chat import Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the dataset 'eli5_category' from HuggingFace Hub, and we only take the first 10k datapoints of the train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"eli5_category\")\n",
    "dataset = dataset['train']\n",
    "dataset = dataset.to_list()\n",
    "dataset = [datapoint for datapoint in dataset if datapoint['selftext'] == '' and 'title' in datapoint and 'answers' in datapoint and datapoint['title'] is not None and datapoint['answers']['text'] is not None]\n",
    "print(\"Dataset length: \", len(dataset))\n",
    "dataset = dataset[:10000]\n",
    "print(\"Dataset length: \", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_sample(sample):\n",
    "    # Replace newline characters with spaces\n",
    "    sample = sample.replace('\\n', ' ')\n",
    "\n",
    "    # Check if the sample has the correct format\n",
    "    if not re.match(r\"^4: .+ 3: .+ 2: .+ 1: .+ 0: .+$\", sample):\n",
    "        print(f\"Skipped datapoint: {sample}\")\n",
    "        return None\n",
    "\n",
    "    # Split the sample into separate answers\n",
    "    split_sample = re.split(' \\d: ', sample)\n",
    "\n",
    "    # Remove the initial number from the first answer\n",
    "    split_sample[0] = re.sub('^\\d: ', '', split_sample[0])\n",
    "\n",
    "    return split_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Create an empty list to store the datapoints\n",
    "QandA = []\n",
    "start_index = 0\n",
    "skipped_dps = 2\n",
    "\n",
    "try:\n",
    "    # Load the previous list of datapoints (useful to resume the process if it was interrupted)\n",
    "    with open('QandA_bis.json', 'r') as f:\n",
    "        QandA = json.load(f)\n",
    "\n",
    "    start_index = len(QandA) + skipped_dps\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load previous data: {e}\")\n",
    "    \n",
    "data_len = len(dataset)\n",
    "start_time = time.time()\n",
    "elapsed_times = []\n",
    "token_costs = []\n",
    "\n",
    "# Iterate over the data\n",
    "for count, datapoint in enumerate(dataset[start_index:], start_index + 1):\n",
    "    print(\"########################################################\")\n",
    "    print(\"Processing datapoint\", count, \"of\", data_len, \"(\", round(count/data_len*100, 2), \"%)\")\n",
    "    print(\"########################################################\")\n",
    "\n",
    "    iteration_start_time = time.time()\n",
    "\n",
    "    chat = Chat.create(\"Score_ELI5_\" + str(count))\n",
    "\n",
    "    Q = datapoint['title']\n",
    "    A = datapoint['answers']['text'][0]\n",
    "\n",
    "    query = \"Given the following question and its correct answer (which was evaluated as 5/5 by a grader), please provide answers that would likely receive lower grades due to varying degrees of factual inaccuracies or misunderstandings. Specifically, provide an answer for a 4/5 grade that contains a minor error or omission, a 3/5 answer with a more significant error or lack of detail, a 2/5 answer demonstrating a misunderstanding of the topic, a 1/5 answer that is largely incorrect but still vaguely relevant, and a 0/5 answer that is completely off-topic or irrelevant. All answers should be plausible and similarly styled to the correct one, but the length can vary. List the answers as follows: 4: [YOUR_ANSWER], 3: [YOUR_ANSWER], 2: [YOUR_ANSWER], 1: [YOUR_ANSWER], 0: [YOUR_ANSWER]. Remove '[YOUR_ANSWER]' in your answer. Question: \" + Q + \" Correct answer: \" + A\n",
    "\n",
    "    # create a chat completion\n",
    "    used_before = Chat.budget()['usage']\n",
    "    bad_A = chat.ask(content=query)\n",
    "    used_after = Chat.budget()['usage']\n",
    "    print(\"Bad answers:\\n\", bad_A.content)\n",
    "\n",
    "    processed_list = process_sample(bad_A.content)\n",
    "    if processed_list is not None:\n",
    "        datapoint_dict = {\n",
    "            \"question\": Q,\n",
    "            \"gold_answer\": A,\n",
    "            \"answer_4\": processed_list[0],\n",
    "            \"answer_3\": processed_list[1],\n",
    "            \"answer_2\": processed_list[2],\n",
    "            \"answer_1\": processed_list[3],\n",
    "            \"answer_0\": processed_list[4],\n",
    "            \"ID\": datapoint['q_id']\n",
    "        }\n",
    "\n",
    "        # Add the datapoint to the list\n",
    "        QandA.append(datapoint_dict)\n",
    "\n",
    "        # Save the list of datapoints as a JSON file\n",
    "        with open('QandA_bis.json', 'w') as f:\n",
    "            json.dump(QandA, f)\n",
    "\n",
    "    iteration_end_time = time.time()\n",
    "\n",
    "    elapsed_time = iteration_end_time - iteration_start_time\n",
    "    elapsed_times.append(elapsed_time)\n",
    "\n",
    "    token_cost = used_after - used_before\n",
    "    token_costs.append(token_cost)\n",
    "\n",
    "    average_time_per_datapoint = sum(elapsed_times) / len(elapsed_times)\n",
    "    remaining_datapoints = data_len - count\n",
    "    estimated_time_remaining = remaining_datapoints * average_time_per_datapoint\n",
    "\n",
    "    print(\"Estimated time remaining: \", round(estimated_time_remaining/60, 2), \"minutes\")\n",
    "\n",
    "    print(\"Tokens used: \", used_after / Chat.budget()['limit'] * 100, \"%\")\n",
    "    print(\"Tokens used in this iteration: \", token_cost)\n",
    "    print(\"Average tokens used per iteration: \", sum(token_costs) / len(token_costs))\n",
    "    tokens_remaining = Chat.budget()['limit'] - used_after\n",
    "    estimated_iterations_remaining = tokens_remaining / ((sum(token_costs) / len(token_costs)))\n",
    "    print(\"Estimated iterations remaining: \", estimated_iterations_remaining)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
